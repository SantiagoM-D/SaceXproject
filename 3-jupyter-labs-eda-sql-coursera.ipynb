{"cells":[{"cell_type":"markdown","metadata":{},"source":["<p style=\"text-align:center\">\n","    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n","    </a>\n","</p>\n","\n","<h1 align=center><font size = 5>Assignment: SQL Notebook for Peer Assignment</font></h1>\n","\n","Estimated time needed: **60** minutes.\n","\n","## Introduction\n","\n","Using this Python notebook you will:\n","\n","1.  Understand the Spacex DataSet\n","2.  Load the dataset  into the corresponding table in a Db2 database\n","3.  Execute SQL queries to answer assignment questions\n"]},{"cell_type":"markdown","metadata":{},"source":["## Overview of the DataSet\n","\n","SpaceX has gained worldwide attention for a series of historic milestones.\n","\n","It is the only private company ever to return a spacecraft from low-earth orbit, which it first accomplished in December 2010.\n","SpaceX advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars wheras other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage.\n","\n","Therefore if we can determine if the first stage will land, we can determine the cost of a launch.\n","\n","This information can be used if an alternate company wants to bid against SpaceX for a rocket launch.\n","\n","This dataset includes a record for each payload carried during a SpaceX mission into outer space.\n"]},{"cell_type":"markdown","metadata":{},"source":["### Download the datasets\n","\n","This assignment requires you to load the spacex dataset.\n","\n","In many cases the dataset to be analyzed is available as a .CSV (comma separated values) file, perhaps on the internet. Click on the link below to download and save the dataset (.CSV file):\n","\n","<a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\" target=\"_blank\">Spacex DataSet</a>\n"]},{"cell_type":"markdown","metadata":{},"source":["### Store the dataset in database table\n","\n","**it is highly recommended to manually load the table using the database console LOAD tool in DB2**.\n","\n","<img src = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload.png\">\n","\n","Now open the Db2 console, open the LOAD tool, Select / Drag the .CSV file for the  dataset, Next create a New Table, and then follow the steps on-screen instructions to load the data. Name the new table as follows:\n","\n","**SPACEXDATASET**\n","\n","**Follow these steps while using old DB2 UI which is having Open Console Screen**\n","\n","**Note:While loading Spacex dataset, ensure that detect datatypes is disabled. Later click on the pencil icon(edit option).**\n","\n","1.  Change the Date Format by manually typing DD-MM-YYYY and timestamp format as DD-MM-YYYY HH\\:MM:SS.\n","\n","    Here you should place the cursor at Date field and manually type as DD-MM-YYYY.\n","\n","2.  Change the PAYLOAD_MASS\\_\\_KG\\_  datatype  to INTEGER.\n","\n","<img src = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload2.png\">\n"]},{"cell_type":"markdown","metadata":{},"source":["**Changes to be considered when having DB2 instance with the new UI having Go to UI screen**\n","\n","*   Refer to this insruction in this <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sign%20up%20for%20IBM%20Cloud%20-%20Create%20Db2%20service%20instance%20-%20Get%20started%20with%20the%20Db2%20console/instructional-labs.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\">link</a> for viewing  the new  Go to UI screen.\n","\n","*   Later click on **Data link(below SQL)**  in the Go to UI screen  and click on **Load Data** tab.\n","\n","*   Later browse for the downloaded spacex file.\n","\n","<img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/browsefile.png\" width=\"800\"/>\n","\n","*   Once done select the schema andload the file.\n","\n"," <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/spacexload3.png\" width=\"800\"/>\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pip install sqlalchemy==1.3.9\n","pip install ibm_db_sa\n","pip install ipython-sql"]},{"cell_type":"markdown","metadata":{},"source":["### Connect to the database\n","\n","Let us first load the SQL extension and establish a connection with the database\n"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["%load_ext sql\n","import csv, sqlite3\n","\n","con = sqlite3.connect(\"spxdb.db\")\n","cur = con.cursor()\n","\n","%sql sqlite:///spxdb.db\n"]},{"cell_type":"code","execution_count":61,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '22-05-2012' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '29-09-2013' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '18-04-2014' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '14-07-2014' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '21-09-2014' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '14-04-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '27-04-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '28-06-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '22-12-2015' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '17-01-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '27-05-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '15-06-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '18-07-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '14-08-2016' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '14-01-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '19-02-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '16-03-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '30-03-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '15-05-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '23-06-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '25-06-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '14-08-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '24-08-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '30-10-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '15-12-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '23-12-2017' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '31-01-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '22-02-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '30-03-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '18-04-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '22-05-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '29-06-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '22-07-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '25-07-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '15-11-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '23-12-2018' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '22-02-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '24-05-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '25-07-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '17-12-2019' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '19-01-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '29-01-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '17-02-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '18-03-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '22-04-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '30-05-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '13-06-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '30-06-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '20-07-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '18-08-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '30-08-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '18-10-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '24-10-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '16-11-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '21-11-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n","C:\\Users\\sjmon\\AppData\\Local\\Temp\\ipykernel_10424\\2998972888.py:5: UserWarning: Parsing '25-11-2020' in DD/MM/YYYY format. Provide format or specify infer_datetime_format=True for consistent parsing.\n","  df['Date'] = pd.to_datetime(df['Date'])\n"]}],"source":["import pandas as pd\n","import sqlalchemy\n","import datetime\n","df = pd.read_csv('Spacex.csv')\n","df['Date'] = pd.to_datetime(df['Date'])\n","df['Time (UTC)'] = pd.to_datetime(df['Time (UTC)'], format='%H:%M:%S').dt.time\n","df.dtypes\n","df.rename(columns = {'Landing _Outcome':'Landing_Outcome'}, inplace = True)\n","\n"]},{"cell_type":"code","execution_count":62,"metadata":{},"outputs":[{"data":{"text/plain":["101"]},"execution_count":62,"metadata":{},"output_type":"execute_result"}],"source":["import pandas\n","import sqlalchemy\n","import datetime\n","df.to_sql(\"Spacex\", \n","    con, \n","    if_exists='replace', \n","    index=False,\n","    method=\"multi\")"]},{"cell_type":"markdown","metadata":{},"source":["**DB2 magic in case of old UI service credentials.**\n","\n","In the next cell enter your db2 connection string. Recall you created Service Credentials for your Db2 instance before. From the **uri** field of your Db2 service credentials copy everything after db2:// (except the double quote at the end) and paste it in the cell below after ibm_db_sa://\n","\n","<img src =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/FinalModule_edX/images/URI.jpg\">\n","\n","in the following format\n","\n","**%sql ibm_db_sa://my-username:my-password\\@my-hostname:my-port/my-db-name**\n","\n","**DB2 magic in case of new UI service credentials.**\n","\n","<img src =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/images/servicecredentials.png\" width=600>  \n","\n","*   Use the following format.\n","\n","*   Add security=SSL at the end\n","\n","**%sql ibm_db_sa://my-username:my-password\\@my-hostname:my-port/my-db-name?security=SSL**\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["%sql ibm_db_sa://"]},{"cell_type":"markdown","metadata":{},"source":["## Tasks\n","\n","Now write and execute SQL queries to solve the assignment tasks.\n","\n","### Task 1\n","\n","##### Display the names of the unique launch sites  in the space mission\n"]},{"cell_type":"code","execution_count":63,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * sqlite:///spxdb.db\n","Done.\n"]},{"data":{"text/html":["<table>\n","    <tr>\n","        <th>Launch_Site</th>\n","    </tr>\n","    <tr>\n","        <td>CCAFS LC-40</td>\n","    </tr>\n","    <tr>\n","        <td>VAFB SLC-4E</td>\n","    </tr>\n","    <tr>\n","        <td>KSC LC-39A</td>\n","    </tr>\n","    <tr>\n","        <td>CCAFS SLC-40</td>\n","    </tr>\n","</table>"],"text/plain":["[('CCAFS LC-40',), ('VAFB SLC-4E',), ('KSC LC-39A',), ('CCAFS SLC-40',)]"]},"execution_count":63,"metadata":{},"output_type":"execute_result"}],"source":["%sql SELECT DISTINCT Launch_Site FROM Spacex"]},{"cell_type":"markdown","metadata":{},"source":["### Task 2\n","\n","##### Display 5 records where launch sites begin with the string 'CCA'\n"]},{"cell_type":"code","execution_count":64,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * sqlite:///spxdb.db\n","Done.\n"]},{"data":{"text/html":["<table>\n","    <tr>\n","        <th>Date</th>\n","        <th>Time (UTC)</th>\n","        <th>Booster_Version</th>\n","        <th>Launch_Site</th>\n","        <th>Payload</th>\n","        <th>PAYLOAD_MASS__KG_</th>\n","        <th>Orbit</th>\n","        <th>Customer</th>\n","        <th>Mission_Outcome</th>\n","        <th>Landing_Outcome</th>\n","    </tr>\n","    <tr>\n","        <td>2010-04-06 00:00:00</td>\n","        <td>18:45:00.000000</td>\n","        <td>F9 v1.0  B0003</td>\n","        <td>CCAFS LC-40</td>\n","        <td>Dragon Spacecraft Qualification Unit</td>\n","        <td>0</td>\n","        <td>LEO</td>\n","        <td>SpaceX</td>\n","        <td>Success</td>\n","        <td>Failure (parachute)</td>\n","    </tr>\n","    <tr>\n","        <td>2010-08-12 00:00:00</td>\n","        <td>15:43:00.000000</td>\n","        <td>F9 v1.0  B0004</td>\n","        <td>CCAFS LC-40</td>\n","        <td>Dragon demo flight C1, two CubeSats, barrel of Brouere cheese</td>\n","        <td>0</td>\n","        <td>LEO (ISS)</td>\n","        <td>NASA (COTS) NRO</td>\n","        <td>Success</td>\n","        <td>Failure (parachute)</td>\n","    </tr>\n","    <tr>\n","        <td>2012-05-22 00:00:00</td>\n","        <td>07:44:00.000000</td>\n","        <td>F9 v1.0  B0005</td>\n","        <td>CCAFS LC-40</td>\n","        <td>Dragon demo flight C2</td>\n","        <td>525</td>\n","        <td>LEO (ISS)</td>\n","        <td>NASA (COTS)</td>\n","        <td>Success</td>\n","        <td>No attempt</td>\n","    </tr>\n","    <tr>\n","        <td>2012-08-10 00:00:00</td>\n","        <td>00:35:00.000000</td>\n","        <td>F9 v1.0  B0006</td>\n","        <td>CCAFS LC-40</td>\n","        <td>SpaceX CRS-1</td>\n","        <td>500</td>\n","        <td>LEO (ISS)</td>\n","        <td>NASA (CRS)</td>\n","        <td>Success</td>\n","        <td>No attempt</td>\n","    </tr>\n","    <tr>\n","        <td>2013-01-03 00:00:00</td>\n","        <td>15:10:00.000000</td>\n","        <td>F9 v1.0  B0007</td>\n","        <td>CCAFS LC-40</td>\n","        <td>SpaceX CRS-2</td>\n","        <td>677</td>\n","        <td>LEO (ISS)</td>\n","        <td>NASA (CRS)</td>\n","        <td>Success</td>\n","        <td>No attempt</td>\n","    </tr>\n","</table>"],"text/plain":["[('2010-04-06 00:00:00', '18:45:00.000000', 'F9 v1.0  B0003', 'CCAFS LC-40', 'Dragon Spacecraft Qualification Unit', 0, 'LEO', 'SpaceX', 'Success', 'Failure (parachute)'),\n"," ('2010-08-12 00:00:00', '15:43:00.000000', 'F9 v1.0  B0004', 'CCAFS LC-40', 'Dragon demo flight C1, two CubeSats, barrel of Brouere cheese', 0, 'LEO (ISS)', 'NASA (COTS) NRO', 'Success', 'Failure (parachute)'),\n"," ('2012-05-22 00:00:00', '07:44:00.000000', 'F9 v1.0  B0005', 'CCAFS LC-40', 'Dragon demo flight C2', 525, 'LEO (ISS)', 'NASA (COTS)', 'Success', 'No attempt'),\n"," ('2012-08-10 00:00:00', '00:35:00.000000', 'F9 v1.0  B0006', 'CCAFS LC-40', 'SpaceX CRS-1', 500, 'LEO (ISS)', 'NASA (CRS)', 'Success', 'No attempt'),\n"," ('2013-01-03 00:00:00', '15:10:00.000000', 'F9 v1.0  B0007', 'CCAFS LC-40', 'SpaceX CRS-2', 677, 'LEO (ISS)', 'NASA (CRS)', 'Success', 'No attempt')]"]},"execution_count":64,"metadata":{},"output_type":"execute_result"}],"source":["%sql SELECT * FROM Spacex WHERE Launch_Site LIKE 'CCA%' LIMIT 5"]},{"cell_type":"markdown","metadata":{},"source":["### Task 3\n","\n","##### Display the total payload mass carried by boosters launched by NASA (CRS)\n"]},{"cell_type":"code","execution_count":65,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * sqlite:///spxdb.db\n","Done.\n"]},{"data":{"text/html":["<table>\n","    <tr>\n","        <th>Customer</th>\n","        <th>total</th>\n","    </tr>\n","    <tr>\n","        <td>NASA (CRS)</td>\n","        <td>45596</td>\n","    </tr>\n","</table>"],"text/plain":["[('NASA (CRS)', 45596)]"]},"execution_count":65,"metadata":{},"output_type":"execute_result"}],"source":["%sql SELECT Customer, sum(PAYLOAD_MASS__KG_) as total FROM Spacex WHERE Customer = 'NASA (CRS)' GROUP BY Customer"]},{"cell_type":"markdown","metadata":{},"source":["### Task 4\n","\n","##### Display average payload mass carried by booster version F9 v1.1\n"]},{"cell_type":"code","execution_count":66,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * sqlite:///spxdb.db\n","Done.\n"]},{"data":{"text/html":["<table>\n","    <tr>\n","        <th>Booster_Version</th>\n","        <th>total</th>\n","    </tr>\n","    <tr>\n","        <td>F9 B4  B1039.2</td>\n","        <td>2647.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4  B1040.2</td>\n","        <td>5384.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4  B1041.2</td>\n","        <td>9600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4  B1043.2</td>\n","        <td>6460.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4 B1039.1</td>\n","        <td>3310.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4 B1040.1</td>\n","        <td>4990.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4 B1041.1</td>\n","        <td>9600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4 B1042.1</td>\n","        <td>3500.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4 B1043.1</td>\n","        <td>5000.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4 B1044</td>\n","        <td>6092.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4 B1045.1</td>\n","        <td>362.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B4 B1045.2</td>\n","        <td>2697.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5  B1046.1</td>\n","        <td>3600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1046.2</td>\n","        <td>5800.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1046.3</td>\n","        <td>4000.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1046.4</td>\n","        <td>12050.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1047.2</td>\n","        <td>5300.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1047.3 </td>\n","        <td>6500.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1048.2</td>\n","        <td>3000.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1048.3</td>\n","        <td>4850.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1048.4</td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1048.5</td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1049.2</td>\n","        <td>9600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1049.3</td>\n","        <td>13620.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1049.4</td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1049.5</td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1049.6</td>\n","        <td>15440.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1049.7 </td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1051.2 </td>\n","        <td>4200.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1051.3</td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1051.4</td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1051.5</td>\n","        <td>14932.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1051.6</td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1056.2 </td>\n","        <td>2268.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1056.3 </td>\n","        <td>6956.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1056.4</td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1058.2 </td>\n","        <td>5500.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1058.3 </td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1058.4 </td>\n","        <td>2972.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1059.2</td>\n","        <td>1977.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1059.3</td>\n","        <td>15410.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1059.4</td>\n","        <td>3130.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1060.2 </td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1060.3</td>\n","        <td>15600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1047.1</td>\n","        <td>7075.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1048.1</td>\n","        <td>9600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1049.1</td>\n","        <td>7060.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1050</td>\n","        <td>2500.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1051.1</td>\n","        <td>12055.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1054</td>\n","        <td>4400.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1056.1 </td>\n","        <td>2495.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1058.1 </td>\n","        <td>12530.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1059.1</td>\n","        <td>2617.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1060.1</td>\n","        <td>4311.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1061.1 </td>\n","        <td>12500.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1062.1</td>\n","        <td>4311.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5B1063.1</td>\n","        <td>1192.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT  B1021.2</td>\n","        <td>5300.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT  B1029.2</td>\n","        <td>3669.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT  B1031.2</td>\n","        <td>5200.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT  B1032.2</td>\n","        <td>4230.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT  B1035.2</td>\n","        <td>2205.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT  B1036.2</td>\n","        <td>9600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT  B1038.2</td>\n","        <td>2150.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1019</td>\n","        <td>2034.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1020</td>\n","        <td>5271.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1021.1</td>\n","        <td>3136.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1022</td>\n","        <td>4696.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1023.1</td>\n","        <td>3100.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1024</td>\n","        <td>3600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1025.1</td>\n","        <td>2257.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1026</td>\n","        <td>4600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1029.1</td>\n","        <td>9600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1030</td>\n","        <td>5600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1031.1</td>\n","        <td>2490.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1032.1</td>\n","        <td>5300.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1034</td>\n","        <td>6070.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1035.1</td>\n","        <td>2708.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1036.1</td>\n","        <td>9600.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1037</td>\n","        <td>6761.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1038.1</td>\n","        <td>475.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.0  B0003</td>\n","        <td>0.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.0  B0004</td>\n","        <td>0.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.0  B0005</td>\n","        <td>525.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.0  B0006</td>\n","        <td>500.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.0  B0007</td>\n","        <td>677.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1</td>\n","        <td>2928.4</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1  B1003</td>\n","        <td>500.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1 B1010</td>\n","        <td>2216.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1 B1011</td>\n","        <td>4428.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1 B1012</td>\n","        <td>2395.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1 B1013</td>\n","        <td>570.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1 B1014</td>\n","        <td>4159.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1 B1015</td>\n","        <td>1898.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1 B1016</td>\n","        <td>4707.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1 B1017</td>\n","        <td>553.0</td>\n","    </tr>\n","    <tr>\n","        <td>F9 v1.1 B1018</td>\n","        <td>1952.0</td>\n","    </tr>\n","</table>"],"text/plain":["[('F9 B4  B1039.2', 2647.0),\n"," ('F9 B4  B1040.2', 5384.0),\n"," ('F9 B4  B1041.2', 9600.0),\n"," ('F9 B4  B1043.2', 6460.0),\n"," ('F9 B4 B1039.1', 3310.0),\n"," ('F9 B4 B1040.1', 4990.0),\n"," ('F9 B4 B1041.1', 9600.0),\n"," ('F9 B4 B1042.1', 3500.0),\n"," ('F9 B4 B1043.1', 5000.0),\n"," ('F9 B4 B1044', 6092.0),\n"," ('F9 B4 B1045.1', 362.0),\n"," ('F9 B4 B1045.2', 2697.0),\n"," ('F9 B5  B1046.1', 3600.0),\n"," ('F9 B5 B1046.2', 5800.0),\n"," ('F9 B5 B1046.3', 4000.0),\n"," ('F9 B5 B1046.4', 12050.0),\n"," ('F9 B5 B1047.2', 5300.0),\n"," ('F9 B5 B1047.3 ', 6500.0),\n"," ('F9 B5 B1048.2', 3000.0),\n"," ('F9 B5 B1048.3', 4850.0),\n"," ('F9 B5 B1048.4', 15600.0),\n"," ('F9 B5 B1048.5', 15600.0),\n"," ('F9 B5 B1049.2', 9600.0),\n"," ('F9 B5 B1049.3', 13620.0),\n"," ('F9 B5 B1049.4', 15600.0),\n"," ('F9 B5 B1049.5', 15600.0),\n"," ('F9 B5 B1049.6', 15440.0),\n"," ('F9 B5 B1049.7 ', 15600.0),\n"," ('F9 B5 B1051.2 ', 4200.0),\n"," ('F9 B5 B1051.3', 15600.0),\n"," ('F9 B5 B1051.4', 15600.0),\n"," ('F9 B5 B1051.5', 14932.0),\n"," ('F9 B5 B1051.6', 15600.0),\n"," ('F9 B5 B1056.2 ', 2268.0),\n"," ('F9 B5 B1056.3 ', 6956.0),\n"," ('F9 B5 B1056.4', 15600.0),\n"," ('F9 B5 B1058.2 ', 5500.0),\n"," ('F9 B5 B1058.3 ', 15600.0),\n"," ('F9 B5 B1058.4 ', 2972.0),\n"," ('F9 B5 B1059.2', 1977.0),\n"," ('F9 B5 B1059.3', 15410.0),\n"," ('F9 B5 B1059.4', 3130.0),\n"," ('F9 B5 B1060.2 ', 15600.0),\n"," ('F9 B5 B1060.3', 15600.0),\n"," ('F9 B5B1047.1', 7075.0),\n"," ('F9 B5B1048.1', 9600.0),\n"," ('F9 B5B1049.1', 7060.0),\n"," ('F9 B5B1050', 2500.0),\n"," ('F9 B5B1051.1', 12055.0),\n"," ('F9 B5B1054', 4400.0),\n"," ('F9 B5B1056.1 ', 2495.0),\n"," ('F9 B5B1058.1 ', 12530.0),\n"," ('F9 B5B1059.1', 2617.0),\n"," ('F9 B5B1060.1', 4311.0),\n"," ('F9 B5B1061.1 ', 12500.0),\n"," ('F9 B5B1062.1', 4311.0),\n"," ('F9 B5B1063.1', 1192.0),\n"," ('F9 FT  B1021.2', 5300.0),\n"," ('F9 FT  B1029.2', 3669.0),\n"," ('F9 FT  B1031.2', 5200.0),\n"," ('F9 FT  B1032.2', 4230.0),\n"," ('F9 FT  B1035.2', 2205.0),\n"," ('F9 FT  B1036.2', 9600.0),\n"," ('F9 FT  B1038.2', 2150.0),\n"," ('F9 FT B1019', 2034.0),\n"," ('F9 FT B1020', 5271.0),\n"," ('F9 FT B1021.1', 3136.0),\n"," ('F9 FT B1022', 4696.0),\n"," ('F9 FT B1023.1', 3100.0),\n"," ('F9 FT B1024', 3600.0),\n"," ('F9 FT B1025.1', 2257.0),\n"," ('F9 FT B1026', 4600.0),\n"," ('F9 FT B1029.1', 9600.0),\n"," ('F9 FT B1030', 5600.0),\n"," ('F9 FT B1031.1', 2490.0),\n"," ('F9 FT B1032.1', 5300.0),\n"," ('F9 FT B1034', 6070.0),\n"," ('F9 FT B1035.1', 2708.0),\n"," ('F9 FT B1036.1', 9600.0),\n"," ('F9 FT B1037', 6761.0),\n"," ('F9 FT B1038.1', 475.0),\n"," ('F9 v1.0  B0003', 0.0),\n"," ('F9 v1.0  B0004', 0.0),\n"," ('F9 v1.0  B0005', 525.0),\n"," ('F9 v1.0  B0006', 500.0),\n"," ('F9 v1.0  B0007', 677.0),\n"," ('F9 v1.1', 2928.4),\n"," ('F9 v1.1  B1003', 500.0),\n"," ('F9 v1.1 B1010', 2216.0),\n"," ('F9 v1.1 B1011', 4428.0),\n"," ('F9 v1.1 B1012', 2395.0),\n"," ('F9 v1.1 B1013', 570.0),\n"," ('F9 v1.1 B1014', 4159.0),\n"," ('F9 v1.1 B1015', 1898.0),\n"," ('F9 v1.1 B1016', 4707.0),\n"," ('F9 v1.1 B1017', 553.0),\n"," ('F9 v1.1 B1018', 1952.0)]"]},"execution_count":66,"metadata":{},"output_type":"execute_result"}],"source":["%sql SELECT Booster_Version, avg(PAYLOAD_MASS__KG_) as total FROM Spacex GROUP BY Booster_Version"]},{"cell_type":"markdown","metadata":{},"source":["### Task 5\n","\n","##### List the date when the first successful landing outcome in ground pad was acheived.\n","\n","*Hint:Use min function*\n"]},{"cell_type":"code","execution_count":71,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * sqlite:///spxdb.db\n","Done.\n"]},{"data":{"text/html":["<table>\n","    <tr>\n","        <th>Landing_Outcome</th>\n","        <th>first_date</th>\n","    </tr>\n","    <tr>\n","        <td>Controlled (ocean)</td>\n","        <td>2014-04-18 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>Failure</td>\n","        <td>2018-05-12 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>Failure (drone ship)</td>\n","        <td>2015-04-14 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>Failure (parachute)</td>\n","        <td>2010-04-06 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>No attempt</td>\n","        <td>2012-05-22 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>No attempt </td>\n","        <td>2019-06-08 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>Precluded (drone ship)</td>\n","        <td>2015-06-28 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>Success</td>\n","        <td>2018-03-12 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>Success (drone ship)</td>\n","        <td>2016-05-27 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>Success (ground pad)</td>\n","        <td>2015-12-22 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>Uncontrolled (ocean)</td>\n","        <td>2013-09-29 00:00:00</td>\n","    </tr>\n","</table>"],"text/plain":["[('Controlled (ocean)', '2014-04-18 00:00:00'),\n"," ('Failure', '2018-05-12 00:00:00'),\n"," ('Failure (drone ship)', '2015-04-14 00:00:00'),\n"," ('Failure (parachute)', '2010-04-06 00:00:00'),\n"," ('No attempt', '2012-05-22 00:00:00'),\n"," ('No attempt ', '2019-06-08 00:00:00'),\n"," ('Precluded (drone ship)', '2015-06-28 00:00:00'),\n"," ('Success', '2018-03-12 00:00:00'),\n"," ('Success (drone ship)', '2016-05-27 00:00:00'),\n"," ('Success (ground pad)', '2015-12-22 00:00:00'),\n"," ('Uncontrolled (ocean)', '2013-09-29 00:00:00')]"]},"execution_count":71,"metadata":{},"output_type":"execute_result"}],"source":["#%sql SELECT Landing_Outcome, min(Date) as first_date FROM Spacex WHERE Landing_Outcome = 'Success (ground pad)' GROUP BY Landing_Outcome\n","%sql SELECT Landing_Outcome, min(Date) as first_date FROM Spacex  GROUP BY Landing_Outcome"]},{"cell_type":"markdown","metadata":{},"source":["### Task 6\n","\n","##### List the names of the boosters which have success in drone ship and have payload mass greater than 4000 but less than 6000\n"]},{"cell_type":"code","execution_count":72,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * sqlite:///spxdb.db\n","Done.\n"]},{"data":{"text/html":["<table>\n","    <tr>\n","        <th>Booster_Version</th>\n","        <th>Landing_Outcome</th>\n","        <th>PAYLOAD_MASS__KG_</th>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1022</td>\n","        <td>Success (drone ship)</td>\n","        <td>4696</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT B1026</td>\n","        <td>Success (drone ship)</td>\n","        <td>4600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT  B1021.2</td>\n","        <td>Success (drone ship)</td>\n","        <td>5300</td>\n","    </tr>\n","    <tr>\n","        <td>F9 FT  B1031.2</td>\n","        <td>Success (drone ship)</td>\n","        <td>5200</td>\n","    </tr>\n","</table>"],"text/plain":["[('F9 FT B1022', 'Success (drone ship)', 4696),\n"," ('F9 FT B1026', 'Success (drone ship)', 4600),\n"," ('F9 FT  B1021.2', 'Success (drone ship)', 5300),\n"," ('F9 FT  B1031.2', 'Success (drone ship)', 5200)]"]},"execution_count":72,"metadata":{},"output_type":"execute_result"}],"source":["%sql SELECT Booster_Version, Landing_Outcome, PAYLOAD_MASS__KG_ FROM Spacex WHERE Landing_Outcome = 'Success (drone ship)' and PAYLOAD_MASS__KG_ BETWEEN 4000 AND 6000"]},{"cell_type":"markdown","metadata":{},"source":["### Task 7\n","\n","##### List the total number of successful and failure mission outcomes\n"]},{"cell_type":"code","execution_count":75,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * sqlite:///spxdb.db\n","Done.\n"]},{"data":{"text/html":["<table>\n","    <tr>\n","        <th>Mission_Outcome</th>\n","        <th>Number</th>\n","    </tr>\n","    <tr>\n","        <td>Failure (in flight)</td>\n","        <td>1</td>\n","    </tr>\n","    <tr>\n","        <td>Success</td>\n","        <td>98</td>\n","    </tr>\n","    <tr>\n","        <td>Success </td>\n","        <td>1</td>\n","    </tr>\n","    <tr>\n","        <td>Success (payload status unclear)</td>\n","        <td>1</td>\n","    </tr>\n","</table>"],"text/plain":["[('Failure (in flight)', 1),\n"," ('Success', 98),\n"," ('Success ', 1),\n"," ('Success (payload status unclear)', 1)]"]},"execution_count":75,"metadata":{},"output_type":"execute_result"}],"source":["%sql SELECT DISTINCT Mission_Outcome, count(*) as Number FROM Spacex GROUP BY Mission_Outcome"]},{"cell_type":"markdown","metadata":{},"source":["### Task 8\n","\n","##### List the   names of the booster_versions which have carried the maximum payload mass. Use a subquery\n"]},{"cell_type":"code","execution_count":78,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * sqlite:///spxdb.db\n","Done.\n"]},{"data":{"text/html":["<table>\n","    <tr>\n","        <th>Booster_Version</th>\n","        <th>PAYLOAD_MASS__KG_</th>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1048.4</td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1049.4</td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1051.3</td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1056.4</td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1048.5</td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1051.4</td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1049.5</td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1060.2 </td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1058.3 </td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1051.6</td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1060.3</td>\n","        <td>15600</td>\n","    </tr>\n","    <tr>\n","        <td>F9 B5 B1049.7 </td>\n","        <td>15600</td>\n","    </tr>\n","</table>"],"text/plain":["[('F9 B5 B1048.4', 15600),\n"," ('F9 B5 B1049.4', 15600),\n"," ('F9 B5 B1051.3', 15600),\n"," ('F9 B5 B1056.4', 15600),\n"," ('F9 B5 B1048.5', 15600),\n"," ('F9 B5 B1051.4', 15600),\n"," ('F9 B5 B1049.5', 15600),\n"," ('F9 B5 B1060.2 ', 15600),\n"," ('F9 B5 B1058.3 ', 15600),\n"," ('F9 B5 B1051.6', 15600),\n"," ('F9 B5 B1060.3', 15600),\n"," ('F9 B5 B1049.7 ', 15600)]"]},"execution_count":78,"metadata":{},"output_type":"execute_result"}],"source":["%sql SELECT Booster_Version, PAYLOAD_MASS__KG_ FROM Spacex WHERE PAYLOAD_MASS__KG_ = (select max(PAYLOAD_MASS__KG_) from Spacex)"]},{"cell_type":"markdown","metadata":{},"source":["### Task 9\n","\n","##### List the failed landing_outcomes in drone ship, their booster versions, and launch site names for in year 2015\n"]},{"cell_type":"code","execution_count":86,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * sqlite:///spxdb.db\n","Done.\n"]},{"data":{"text/html":["<table>\n","    <tr>\n","        <th>Landing_Outcome</th>\n","        <th>Booster_Version</th>\n","        <th>Launch_Site</th>\n","        <th>Date</th>\n","    </tr>\n","    <tr>\n","        <td>Failure (drone ship)</td>\n","        <td>F9 v1.1 B1012</td>\n","        <td>CCAFS LC-40</td>\n","        <td>2015-10-01 00:00:00</td>\n","    </tr>\n","    <tr>\n","        <td>Failure (drone ship)</td>\n","        <td>F9 v1.1 B1015</td>\n","        <td>CCAFS LC-40</td>\n","        <td>2015-04-14 00:00:00</td>\n","    </tr>\n","</table>"],"text/plain":["[('Failure (drone ship)', 'F9 v1.1 B1012', 'CCAFS LC-40', '2015-10-01 00:00:00'),\n"," ('Failure (drone ship)', 'F9 v1.1 B1015', 'CCAFS LC-40', '2015-04-14 00:00:00')]"]},"execution_count":86,"metadata":{},"output_type":"execute_result"}],"source":["%sql SELECT Landing_Outcome, Booster_Version,Launch_Site, Date FROM Spacex WHERE Landing_Outcome like'Fa%' AND CAST(SUBSTR(Date, 1, 4) AS integer) = 2015\n"]},{"cell_type":"markdown","metadata":{},"source":["### Task 10\n","\n","##### Rank the count of landing outcomes (such as Failure (drone ship) or Success (ground pad)) between the date 2010-06-04 and 2017-03-20, in descending order\n"]},{"cell_type":"code","execution_count":90,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":[" * sqlite:///spxdb.db\n","Done.\n"]},{"data":{"text/html":["<table>\n","    <tr>\n","        <th>Landing_Outcome</th>\n","        <th>Count</th>\n","    </tr>\n","    <tr>\n","        <td>Success (ground pad)</td>\n","        <td>5</td>\n","    </tr>\n","    <tr>\n","        <td>Failure (drone ship)</td>\n","        <td>5</td>\n","    </tr>\n","</table>"],"text/plain":["[('Success (ground pad)', 5), ('Failure (drone ship)', 5)]"]},"execution_count":90,"metadata":{},"output_type":"execute_result"}],"source":["%sql SELECT DISTINCT Landing_Outcome, count(*) as Count FROM Spacex WHERE Landing_Outcome in ('Failure (drone ship)','Success (ground pad)') AND Date BETWEEN '2010-06-04 00:00:01' AND '2017-03-20 23:59:59' GROUP BY Landing_Outcome ORDER BY Count DESC"]},{"cell_type":"markdown","metadata":{},"source":["### Reference Links\n","\n","*   <a href =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20String%20Patterns%20-%20Sorting%20-%20Grouping/instructional-labs.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01&origin=www.coursera.org\">Hands-on Lab : String Patterns, Sorting and Grouping</a>\n","\n","*   <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Built-in%20functions%20/Hands-on_Lab__Built-in_Functions.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01&origin=www.coursera.org\">Hands-on Lab: Built-in functions</a>\n","\n","*   <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sub-queries%20and%20Nested%20SELECTs%20/instructional-labs.md.html?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01&origin=www.coursera.org\">Hands-on Lab : Sub-queries and Nested SELECT Statements</a>\n","\n","*   <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-3-SQLmagic.ipynb?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\">Hands-on Tutorial: Accessing Databases with SQL magic</a>\n","\n","*   <a href= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-4-Analyzing.ipynb?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDS0321ENSkillsNetwork26802033-2022-01-01\">Hands-on Lab: Analyzing a real World Data Set</a>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Author(s)\n","\n","<h4> Lakshmi Holla </h4>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Change log\n","\n","| Date       | Version | Changed by    | Change Description        |\n","| ---------- | ------- | ------------- | ------------------------- |\n","| 2021-10-12 | 0.4     | Lakshmi Holla | Changed markdown          |\n","| 2021-08-24 | 0.3     | Lakshmi Holla | Added library update      |\n","| 2021-07-09 | 0.2     | Lakshmi Holla | Changes made in magic sql |\n","| 2021-05-20 | 0.1     | Lakshmi Holla | Created Initial Version   |\n"]},{"cell_type":"markdown","metadata":{},"source":["## <h3 align=\"center\"> © IBM Corporation 2021. All rights reserved. <h3/>\n"]},{"cell_type":"markdown","metadata":{},"source":["## Other Contributors\n","\n","<h4> Rav Ahuja </h4>\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"bbbb3348bcc022c2e310b99d4a265eec44051c20dd08a747441feebe1fcd541b"}}},"nbformat":4,"nbformat_minor":4}
